---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---


# About me
I am currently a first-year PhD student at UW-Madison, where I am fortunately advised by Prof. <a href="https://pages.cs.wisc.edu/~sharonli/">Sharon Li</a>. I received the B.E. and M.E. in Computer Science and Technology from HUST. <br>
My current research interests lie in RL algorithms for LLM/MLLM, especially on alignment and reasoning.

<!-- ## News -->
## üî• News
- 2026/01 GEB (General Exploratory Bonus for RLHF) is accepted by ICLR2026
- 2025/11 GEB (General Exploratory Bonus for RLHF) is selected as oral presentation in ResponsibleFM@NeurIPS2026.
- 2025/05 Free Process Rewards without Process Labels is accepted by ICML2025
- 2025/01 PQM (Process Reward Model with Q-value Rankings) is accepted by ICLR2025
- 2024/02 1 paper got accepted by Findings of NAACL2024
- 2023/10 I received National Scholarship (Top 3% nationwide) 
- 2023/05 1 paper got accepted by ACL 2023 main conference


## üìù Selected Publications 

<font size=2> (See full list in the publication section or <a href="https://scholar.google.com/citations?user=hK19TbcAAAAJ&hl=zh-CN">[google scholar]</a>)</font>

- LAD: Learning Advantage Distribution for Reasoning <a href="https://arxiv.org/pdf/2602.20132">[pdf]</a>  <a href="https://github.com/WindyLee0822/LAD">[code]</a> <br>
<font size=3> <b>Wendi Li</b>, Sharon Li </font><br>

- General Exploratory Bonus for Optimistic Exploration in RLHF <a href="https://arxiv.org/pdf/2510.03269">[pdf]</a> <a href="https://github.com/WindyLee0822/GEB">[code]</a>  <b>(ICLR2026, ResponsibleFM@NeurIPS2026 Oral)</b>    <br>
  <font size=3> <b>Wendi Li </b>, Changdae Oh, Yixuan Li</font><br>

- Process Reinforcement through Implicit Rewards <a href="https://arxiv.org/pdf/2502.01456">[pdf]</a> <a href="https://github.com/PRIME-RL/PRIME">[code]</a>   <br>
  <font size=3> Ganqu Cui*, Lifan Yuan*, Zefan Wang*, Hanbin Wang*, <b>Wendi Li* </b>, Bingxiang He*, Yuchen Fan*, Tianyu Yu*, Qixin Xu*, Weize Chen, Jiarui Yuan, Huayu Chen, Kaiyan Zhang, Xingtai Lv, Shuo Wang, Yuan Yao, Xu Han, Hao Peng, Yu Cheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou, Ning Ding </font><br>

- Free Process Rewards without Process Labels <a href="https://arxiv.org/pdf/2412.01981">[pdf]</a> <a href="https://github.com/lifan-yuan/ImplicitPRM">[code]</a> <b>(ICML2025)</b>   <br>
  <font size=3> Lifan Yuan*, <b>Wendi Li*</b>, Huayu Chen, Ganqu Cui, Ning Ding, Kaiyan Zhang, Bowen Zhou, Zhiyuan Liu, Hao Peng </font><br>

- Process Reward Model with Q-value Rankings <a href="https://arxiv.org/pdf/2410.11287">[pdf]</a> <a href="https://github.com/WindyLee0822/Process_Q_Model">[code]</a> <b>(ICLR2025)</b> <br>  <font size=3><b>Wendi Li</b>, Yixuan Li </font><br>

- Reinforcement Learning with Token-level Feedback for Controllable Text Generation <a href="https://arxiv.org/pdf/2403.11558">[pdf]</a> <a href="https://github.com/WindyLee0822/CTG">[code]</a> <b>(Findings of NAACL2024)</b> <br> 
    <font size=3> <b>Wendi Li</b>, Wei Wei, Kaihe Xu, Wenfeng Xie, Dangyang Chen, Yu Cheng </font><br>

- TREA: Tree-Structure Reasoning Schema for Conversational Recommendation <a href="https://arxiv.org/pdf/2307.10543.pdf">[pdf]</a> <a href="https://github.com/WindyLee0822/TREA">[code]</a>  <b>(ACL2023)</b> <br>
  <font size=3><b>Wendi Li</b>, Wei Wei, Xiaoye Qu, Xian-Ling Mao, Ye Yuan, Wenfeng Xie, Dangyang Chen </font><br>





