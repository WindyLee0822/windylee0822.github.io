---
permalink: /publications/
title: ""
excerpt: "Publications"
author_profile: true
redirect_from: 
  - /publications/
  - /publications.html
---

(* denotes equal contribution)

## Preprints

- LAD: Learning Advantage Distribution for Reasoning <a href="https://arxiv.org/pdf/2602.20132">[pdf]</a>  <a href="https://github.com/WindyLee0822/LAD">[code]</a> <br>
- <font size=3> <b>Wendi Li</b>, Sharon Li </font><br>

- Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents <a href="https://arxiv.org/pdf/2602.05073">[pdf]</a> <br>
<font size=3> Changdae Oh, Seongheon Park, To Eun Kim, Jiatong Li, <b>Wendi Li </b>, Samuel Yeh, Xuefeng Du, Hamed Hassani, Paul Bogdan, Dawn Song, Sharon Li </font><br>


- Process Reinforcement through Implicit Rewards <a href="https://arxiv.org/pdf/2502.01456">[pdf]</a> <a href="https://github.com/PRIME-RL/PRIME">[code]</a>   <br>
  <font size=3> Ganqu Cui*, Lifan Yuan*, Zefan Wang*, Hanbin Wang*, <b>Wendi Li* </b>, Bingxiang He*, Yuchen Fan*, Tianyu Yu*, Qixin Xu*, Weize Chen, Jiarui Yuan, Huayu Chen, Kaiyan Zhang, Xingtai Lv, Shuo Wang, Yuan Yao, Xu Han, Hao Peng, Yu Cheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou, Ning Ding </font><br>


## Publications

- General Exploratory Bonus for Optimistic Exploration in RLHF <a href="https://arxiv.org/pdf/2510.03269">[pdf]</a> <a href="https://github.com/WindyLee0822/GEB">[code]</a> <b>(ICLR 2026; ResponsibleFM@NIPS2026 Oral)</b> <br>
    <font size=3>  <b>Wendi Li</b>, Changdae Oh, Yixuan Li</font><br>
    
- Free Process Rewards without Process Labels <a href="https://arxiv.org/pdf/2412.01981">[pdf]</a> <a href="https://github.com/lifan-yuan/ImplicitPRM">[code]</a>  <b>(ICML2025)</b>   <br>
  <font size=3> Lifan Yuan*, <b>Wendi Li*</b>, Huayu Chen, Ganqu Cui, Ning Ding, Kaiyan Zhang, Bowen Zhou, Zhiyuan Liu, Hao Peng </font><br>

- Process Reward Model with Q-value Rankings <a href="https://arxiv.org/pdf/2410.11287">[pdf]</a> <a href="https://github.com/WindyLee0822/Process_Q_Model">[code]</a> <b>(ICLR2025)</b> <br>  <font size=3><b>Wendi Li</b>, Yixuan Li </font><br>

- Reinforcement Learning with Token-level Feedback for Controllable Text Generation <a href="https://arxiv.org/pdf/2403.11558">[pdf]</a> <a href="https://github.com/WindyLee0822/CTG">[code]</a> <b>(Findings of NAACL2024)</b> <br> 
    <font size=3> <b>Wendi Li</b>, Wei Wei, Kaihe Xu, Wenfeng Xie, Dangyang Chen, Yu Cheng </font><br>

- Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue <a href="https://arxiv.org/pdf/2406.02002">[pdf]</a> <a href="https://github.com/WindyLee0822/CTG">[code]</a> <b>(IJCAI2024)</b> <br> 
    <font size=3> Shixuan Fan, Wei Wei, <b>Wendi Li</b>,  Xian-Ling Mao, Wenfeng Xie, Dangyang Chen </font><br>

- TREA: Tree-Structure Reasoning Schema for Conversational Recommendation <a href="https://arxiv.org/pdf/2307.10543.pdf">[pdf]</a> <a href="https://github.com/WindyLee0822/TREA">[code]</a>  <b>(ACL2023)</b> <br>
  <font size=3><b>Wendi Li</b>, Wei Wei, Xiaoye Qu, Xian-Ling Mao, Ye Yuan, Wenfeng Xie, Dangyang Chen </font><br>

- Towards Hierarchical Policy Learning for Conversational Recommendation with Hypergraph-based Reinforcement Learning <a href="https://arxiv.org/pdf/2305.02575.pdf">[pdf]</a> <a href="https://github.com/Snnzhao/DAHCR">[code]</a> <b>(IJCAI2023)</b> <br> 
    <font size=3> Sen Zhao, Wei Wei, Yifan Liu, Ziyang Wang, <b>Wendi Li</b>, Xian-Ling Mao, Shuai Zhu, Minghui Yang, Zujie Wen </font><br>



  
